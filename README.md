# ğŸ¤– Smart Ollama Proxy - æ™ºèƒ½å¤šæ¨¡å‹è·¯ç”±ä»£ç†

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

Smart Ollama Proxy æ˜¯ä¸€ä¸ªæ™ºèƒ½è·¯ç”±ä»£ç†ï¼Œä¸º GitHub Copilotã€Cursor å’Œå…¶ä»– AI å®¢æˆ·ç«¯æä¾›ç»Ÿä¸€çš„æ¨¡å‹è®¿é—®æ¥å£ã€‚å®ƒèƒ½å¤Ÿå°† Ollama API è¯·æ±‚æ™ºèƒ½è·¯ç”±åˆ°ä¸åŒçš„ AI æ¨¡å‹åç«¯ï¼ŒåŒ…æ‹¬æœ¬åœ° Ollama æ¨¡å‹å’Œå¤šç§äº‘ç«¯ AI APIï¼ˆDeepSeekã€OpenAIã€Claudeã€Groqã€ç¡…åŸºæµåŠ¨ã€é€šä¹‰åƒé—®ç­‰ï¼‰ã€‚

é€šè¿‡è¿™ä¸ªä»£ç†ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ GitHub Copilotã€Cursor æˆ–å…¶ä»–æ”¯æŒ Ollama åè®®çš„å®¢æˆ·ç«¯æ— ç¼è®¿é—®æ•°åç§ä¸åŒçš„ AI æ¨¡å‹ï¼Œè€Œæ— éœ€ä¿®æ”¹å®¢æˆ·ç«¯é…ç½®ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **ğŸ”Œ å¤šæ¨¡å‹æ”¯æŒ**: æœ¬åœ° Ollama æ¨¡å‹ + äº‘ç«¯ APIï¼ˆDeepSeekã€ç¡…åŸºæµåŠ¨ã€é€šä¹‰åƒé—®ã€OpenAIã€Claudeã€Groq ç­‰ï¼‰
- **âš™ï¸ æ™ºèƒ½è·¯ç”±**: æ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨è·¯ç”±åˆ°åˆé€‚çš„åç«¯ï¼Œæ”¯æŒåç«¯ä¼˜å…ˆçº§å’Œè‡ªåŠ¨å›é€€
- **ğŸ”§ çµæ´»é…ç½®**: YAML é…ç½® + ç¯å¢ƒå˜é‡ + æœ¬åœ°é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒä¸ªäººå¼€å‘åˆ†æ”¯
- **ğŸ¯ å®Œå…¨å…¼å®¹**: åŸç”Ÿæ”¯æŒ Ollama REST API å’Œ OpenAI å…¼å®¹ API
- **ğŸš€ ç”Ÿäº§å°±ç»ª**: å¼‚æ­¥ FastAPI æ¡†æ¶ï¼Œä¼˜é›…çš„é”™è¯¯å¤„ç†ï¼ŒWindows/Linux/macOS æ”¯æŒ
- **ğŸ“Š æ™ºèƒ½æ—¥å¿—ç³»ç»Ÿ**: æ”¯æŒæµç¨‹ã€æ€§èƒ½ã€æ•°æ®ã€è¿›åº¦å››ç§æ—¥å¿—ç±»å‹ï¼Œå¼‚æ­¥å¤„ç†ï¼Œè¿›åº¦æ¡æ˜¾ç¤º
- **âš¡ æ€§èƒ½ä¼˜åŒ–**: HTTP å®¢æˆ·ç«¯æ± å¤ç”¨ã€å·¥å…·å‹ç¼©ã€æç¤ºè¯å‹ç¼©ã€HTTP ä¼ è¾“å‹ç¼©
- **ğŸ”„ æ¨¡å—åŒ–æ¶æ„**: åç«¯è·¯ç”±å™¨å·¥å‚ + æ ¸å¿ƒç»„ä»¶ï¼Œæ˜“äºæ‰©å±•æ–°çš„æ¨¡å‹æä¾›å•†
- **ğŸ¤– GitHub Copilot é›†æˆ**: æ— ç¼é›†æˆï¼Œæ”¯æŒæ‰€æœ‰æ¨¡å‹
- **ğŸ”§ LiteLLM é›†æˆ**: å¯é€‰é›†æˆ LiteLLM SDKï¼Œè·å¾—é‡è¯•ã€å›é€€ã€æˆæœ¬è·Ÿè¸ªç­‰é«˜çº§åŠŸèƒ½

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç³»ç»Ÿè¦æ±‚
- **Python**: 3.7 æˆ–æ›´é«˜ç‰ˆæœ¬
- **æ“ä½œç³»ç»Ÿ**: Windows / Linux / macOS
- **ç½‘ç»œ**: å¯è®¿é—®äº’è”ç½‘ï¼ˆç”¨äºäº‘ç«¯ APIï¼‰

### 1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®
```bash
git clone <repository-url>
cd smart_ollama_proxy
```

### 2. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 3. é…ç½® API å¯†é’¥

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨æœ¬åœ°é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰
```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶æ¨¡æ¿
cp config.yaml config.local.yaml
# ç¼–è¾‘ config.local.yamlï¼Œæ›¿æ¢ API å¯†é’¥å ä½ç¬¦
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½® API å¯†é’¥
```

è¯¦ç»†é…ç½®è¯´æ˜è¯·å‚è€ƒ [PERSONAL_DEVELOPMENT.md](PERSONAL_DEVELOPMENT.md)ã€‚

### 4. å¯åŠ¨ä»£ç†æœåŠ¡

**Windows ç”¨æˆ·:**
```bash
run.bat
```

**å…¶ä»–ç³»ç»Ÿ:**
```bash
python main.py
# æˆ–ç”Ÿäº§ç¯å¢ƒä½¿ç”¨
uvicorn main:app --host 0.0.0.0 --port 11435 --reload
```

### 5. é…ç½® GitHub Copilot

1. æ‰“å¼€ GitHub Copilot è®¾ç½®
2. è¿›å…¥ "Advanced" æˆ– "ä»£ç†è®¾ç½®"
3. å°† Ollama åœ°å€è®¾ç½®ä¸º `http://localhost:11435`
4. ä¿å­˜è®¾ç½®å¹¶é‡æ–°å¯åŠ¨ Copilot

### 6. éªŒè¯å®‰è£…

è®¿é—®ä»¥ä¸‹åœ°å€éªŒè¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼š
- æœåŠ¡ä¸»é¡µ: http://localhost:11435
- æ¨¡å‹åˆ—è¡¨: http://localhost:11435/api/tags
- API æ–‡æ¡£: http://localhost:11435/docs

## âš™ï¸ é…ç½®è¯´æ˜

Smart Ollama Proxy æ”¯æŒå¤šå±‚é…ç½®ç³»ç»Ÿï¼Œä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼š

1. **ç¯å¢ƒå˜é‡**ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
2. **æœ¬åœ°é…ç½®æ–‡ä»¶** (`config.local.yaml`)
3. **ä¸»é…ç½®æ–‡ä»¶** (`config.yaml`)

### åŸºç¡€é…ç½®
```yaml
proxy:
  port: 11435              # ä»£ç†æœåŠ¡ç«¯å£
  host: "0.0.0.0"          # ç»‘å®šåœ°å€
  log_level: "INFO"        # æ—¥å¿—çº§åˆ«
  # æ˜¯å¦å¯ç”¨è¯¦ç»†çš„JSONæ—¥å¿—è®°å½•ï¼ˆä¼šæ‰“å°å®Œæ•´çš„è¯·æ±‚/å“åº”JSONæ•°æ®ï¼‰
  verbose_json_logging: false
  # æ˜¯å¦å¯ç”¨å·¥å…·å‹ç¼©ä¼˜åŒ–ï¼ˆæ£€æµ‹é‡å¤å·¥å…·åˆ—è¡¨å¹¶å‹ç¼©ï¼‰
  tool_compression_enabled: true
  # æ˜¯å¦å¯ç”¨é‡å¤æç¤ºè¯å‹ç¼©ä¼˜åŒ–ï¼ˆä»å†…å®¹å¤´å¼€å§‹æ¯”å¯¹ä¸ä¸Šæ¬¡å†…å®¹ï¼Œå°†é‡å¤éƒ¨åˆ†æ›¿æ¢ä¸ºæ ‡è®°ï¼‰
  prompt_compression_enabled: true
  # æ˜¯å¦å¯ç”¨HTTPä¼ è¾“å‹ç¼©ï¼ˆgzip/deflateï¼‰
  http_compression_enabled: true

local_ollama:
  base_url: "http://localhost:11434"  # æœ¬åœ° Ollama æœåŠ¡åœ°å€
```

### ç¯å¢ƒå˜é‡é…ç½®
æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½® API å¯†é’¥ï¼Œç¯å¢ƒå˜é‡åæ ¼å¼ï¼š`{æ¨¡å‹ç»„å¤§å†™}_API_KEY`
- DeepSeek: `DEEPSEEK_API_KEY`
- ç¡…åŸºæµåŠ¨: `SILICONFLOW_API_KEY`
- é€šä¹‰åƒé—®: `QWEN_API_KEY`
- é€šä¹‰åƒé—®Coder: `QWEN_CODER_API_KEY`

### æ¨¡å‹é…ç½®ç¤ºä¾‹
```yaml
models:
  deepseek:
    description: "DeepSeek V3.2 ç³»åˆ—æ¨¡å‹"
    available_models:
      deepseek-chat:
        context_length: 128000
        embedding_length: 6400
        capabilities: ["completion", "tools"]
        actual_model: "deepseek-chat"
      deepseek-reasoner:
        context_length: 128000
        embedding_length: 6400
        capabilities: ["completion", "tools", "thinking"]
        actual_model: "deepseek-reasoner"
    
    # åç«¯é…ç½®ï¼ˆæŒ‰é…ç½®é¡ºåºå†³å®šä¼˜å…ˆçº§ï¼Œå¦‚æœå‰ä¸€ä¸ªå¤±è´¥åˆ™å°è¯•åä¸€ä¸ªï¼‰
    litellm_backend:  # ä¼˜å…ˆçº§1
      base_url: "https://api.deepseek.com/v1"
      api_key: "sk-your-deepseek-api-key"
      timeout: 30
      max_retries: 3
      cache: true
    
    openai_backend:   # ä¼˜å…ˆçº§2
      base_url: "https://api.deepseek.com/v1"
      api_key: "sk-your-deepseek-api-key"
      timeout: 30
```

## ğŸ“Š æ™ºèƒ½æ—¥å¿—ç³»ç»Ÿ

Smart Ollama Proxy é‡‡ç”¨ç»Ÿä¸€çš„æ™ºèƒ½æ—¥å¿—ç³»ç»Ÿï¼Œæ”¯æŒå››ç§æ—¥å¿—ç±»å‹ï¼š

### æ—¥å¿—ç±»å‹
| ç±»å‹ | ç”¨é€” | é»˜è®¤è¡Œä¸º |
|------|------|----------|
| **æµç¨‹æ—¥å¿—** (process) | å¸¸è§„æ“ä½œæ—¥å¿—ï¼Œè®°å½•ç¨‹åºè¿è¡ŒçŠ¶æ€ | ä¿å­˜åˆ°æ–‡ä»¶ï¼Œæ§åˆ¶å°æ˜¾ç¤ºï¼Œå¼‚æ­¥å¤„ç† |
| **æ€§èƒ½æ—¥å¿—** (performance) | æ€§èƒ½ç›‘æ§ï¼Œè€—æ—¶ç»Ÿè®¡ï¼Œæ€§èƒ½æŒ‡æ ‡ | ä¿å­˜åˆ°æ–‡ä»¶ï¼Œæ§åˆ¶å°ä¸æ˜¾ç¤ºï¼ŒåŒæ­¥å¤„ç†ï¼ˆéœ€è¦å³æ—¶æ€§ï¼‰ |
| **æ•°æ®æ—¥å¿—** (data) | è¯·æ±‚/å“åº”æ•°æ®ç»Ÿè®¡ | ä¸ä¿å­˜åˆ°æ–‡ä»¶ï¼Œæ§åˆ¶å°æ˜¾ç¤ºæ•°æ®æ‘˜è¦ï¼Œå¼‚æ­¥å¤„ç† |
| **è¿›åº¦æ—¥å¿—** (progress) | å¾ªç¯æ»šåŠ¨è¿›åº¦æ¡æ˜¾ç¤º | ä¸ä¿å­˜åˆ°æ–‡ä»¶ï¼Œæ§åˆ¶å°æ˜¾ç¤ºï¼ŒåŒæ­¥å¤„ç†ï¼ˆéœ€è¦å³æ—¶æ€§ï¼‰ |

### é…ç½®ç¤ºä¾‹
```yaml
logging:
  enabled: true
  log_dir: "logs"
  log_level: "INFO"
  
  # æ—¥å¿—ç±»å‹é…ç½®
  log_types:
    process:
      enabled: true
      save_to_file: true
      show_in_console: true
      async_mode: true
    performance:
      enabled: true
      save_to_file: true
      show_in_console: false
      async_mode: false
    data:
      enabled: true
      save_to_file: false
      show_in_console: false
      async_mode: true
    progress:
      enabled: true
      save_to_file: false
      show_in_console: true
      async_mode: false
```

### è¿›åº¦æ¡æ˜¾ç¤º
ç³»ç»Ÿæ”¯æŒåœ¨é•¿æ—¶é—´æ“ä½œæ—¶æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œå¦‚ï¼š
```
å¤„ç†ä¸­: [||||||||||          ] 50% (5.2s)
```

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ¶æ„å›¾
```
ç”¨æˆ·è¯·æ±‚
    â†“
FastAPI åº”ç”¨ (main.py)
    â†“
æ¨¡å‹è·¯ç”±å™¨ (config_loader.py)
    â†“
åç«¯è·¯ç”±å™¨å·¥å‚ (backend_router_factory.py)
    â†“
[openai_router | litellm_router | ollama_router | mock_router]
    â†“
æ ¸å¿ƒç»„ä»¶ [cache_manager | client_manager | response_converter]
    â†“
HTTPå®¢æˆ·ç«¯æ±  (client_pool.py)
    â†“
å®é™… API è°ƒç”¨
```

### æ ¸å¿ƒç»„ä»¶
- **cache_manager.py**: å·¥å…·ç¼“å­˜å’Œæç¤ºè¯ç¼“å­˜ç®¡ç†
- **client_manager.py**: HTTP å®¢æˆ·ç«¯ç®¡ç†å’Œå¥åº·æ£€æŸ¥
- **response_converter.py**: å“åº”æ ¼å¼è½¬æ¢ï¼ˆOllama â†” OpenAIï¼‰
- **client_pool.py**: HTTP å®¢æˆ·ç«¯æ± ï¼Œå¤ç”¨ç›¸åŒé…ç½®çš„å®¢æˆ·ç«¯

## ğŸ”„ åç«¯è·¯ç”±å™¨æ¶æ„

### è·¯ç”±å™¨ç±»å‹
| è·¯ç”±å™¨ç±» | åç«¯ç±»å‹ | è¯´æ˜ |
|----------|----------|------|
| `OpenAIBackendRouter` | `openai_backend` | OpenAI å…¼å®¹ APIï¼Œä¼˜å…ˆä½¿ç”¨ OpenAI SDKï¼Œå¤±è´¥å›é€€ HTTP |
| `LiteLLMRouter` | `litellm_backend` | ä¸“é—¨ä½¿ç”¨ LiteLLM SDK å¤„ç†è¯·æ±‚ |
| `OllamaBackendRouter` | `ollama` | æœ¬åœ° Ollama æœåŠ¡ |
| `MockBackendRouter` | `mock` | æ¨¡æ‹Ÿåç«¯ï¼Œç”¨äºæµ‹è¯• |

### è‡ªåŠ¨ç±»å‹æ¨æ–­
ç³»ç»Ÿæ ¹æ®é…ç½®çš„ `backend_mode` è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„è·¯ç”±å™¨ï¼š
- `openai_backend` â†’ `OpenAIBackendRouter`
- `litellm_backend` â†’ `LiteLLMRouter`
- æœ¬åœ°æ¨¡å‹ â†’ `OllamaBackendRouter`
- æµ‹è¯•ç¯å¢ƒ â†’ `MockBackendRouter`

### åç«¯ä¼˜å…ˆçº§ä¸å›é€€æœºåˆ¶
å½“æ¨¡å‹ç»„é…ç½®å¤šä¸ªåç«¯æ—¶ï¼Œç³»ç»ŸæŒ‰ç…§é…ç½®æ–‡ä»¶ä¸­çš„é¡ºåºå†³å®šä¼˜å…ˆçº§ï¼š
1. å°è¯•ç¬¬ä¸€ä¸ªåç«¯
2. å¦‚æœå¤±è´¥ï¼ˆç½‘ç»œé”™è¯¯ã€è®¤è¯å¤±è´¥ã€APIé™æµç­‰ï¼‰ï¼Œè‡ªåŠ¨å°è¯•ä¸‹ä¸€ä¸ªåç«¯
3. ç»§ç»­ç›´åˆ°æˆåŠŸæˆ–æ‰€æœ‰åç«¯éƒ½å¤±è´¥

æ—¥å¿—è¾“å‡ºç¤ºä¾‹ï¼š
```
å°è¯•åç«¯ 1/2: deepseek.openai_backend
å°è¯•åç«¯ 2/2: deepseek.litellm_backend
âœ… åç«¯ deepseek.litellm_backend è¯·æ±‚æˆåŠŸ
```

## ğŸ“¡ API æ¥å£

### ğŸ”Œ Ollama å…¼å®¹ API
å®Œå…¨å…¼å®¹ Ollama åŸç”Ÿ APIï¼Œæ”¯æŒæ‰€æœ‰æ ‡å‡†ç«¯ç‚¹ï¼š

```bash
# è·å–æ¨¡å‹åˆ—è¡¨
curl http://localhost:11435/api/tags

# æ–‡æœ¬ç”Ÿæˆ
curl -X POST http://localhost:11435/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-chat",
    "prompt": "è§£é‡Šä¸€ä¸‹Pythonçš„ç”Ÿæˆå™¨",
    "stream": false
  }'
```

### ğŸ¯ OpenAI å…¼å®¹ API
æä¾› OpenAI å…¼å®¹çš„èŠå¤©å®Œæˆæ¥å£ï¼š

```bash
# èŠå¤©å®Œæˆ
curl -X POST http://localhost:11435/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹"},
      {"role": "user", "content": "è§£é‡ŠJavaScripté—­åŒ…çš„æ¦‚å¿µ"}
    ],
    "stream": true
  }'
```

### æ”¯æŒçš„ç«¯ç‚¹
- `GET /api/tags` - è·å–åˆå¹¶çš„æ¨¡å‹åˆ—è¡¨ï¼ˆæœ¬åœ°+è™šæ‹Ÿï¼‰
- `POST /api/generate` - Ollama æ ¼å¼æ–‡æœ¬ç”Ÿæˆ
- `POST /v1/chat/completions` - OpenAI æ ¼å¼èŠå¤©å®Œæˆ
- `GET /api/version` - è·å–ç‰ˆæœ¬ä¿¡æ¯
- `POST /api/show` - è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯
- `ANY /api/{path}` - è½¬å‘å…¶ä»– Ollama API è¯·æ±‚
- `GET /api/client-pool` - æŸ¥çœ‹ HTTP å®¢æˆ·ç«¯æ± çŠ¶æ€

## âš¡ æ€§èƒ½ä¼˜åŒ–

### HTTP å®¢æˆ·ç«¯æ± 
ä¸ºæ¯ä¸ªå”¯ä¸€çš„ `(base_url, api_key, http2)` ç»„åˆåˆ›å»ºå¹¶å¤ç”¨å•ä¸ª `httpx.AsyncClient` å®ä¾‹ï¼Œæ˜¾è‘—æé«˜è¿æ¥å¤ç”¨ç‡ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚

### å·¥å…·å‹ç¼©ä¼˜åŒ–
æ£€æµ‹é‡å¤çš„å·¥å…·åˆ—è¡¨å¹¶å‹ç¼©ï¼Œå‡å°‘è¯·æ±‚ä½“ç§¯ï¼š
- ç›¸åŒå·¥å…·åˆ—è¡¨åªå‘é€ä¸€æ¬¡
- åç»­è¯·æ±‚å¼•ç”¨å·¥å…· ID
- æ˜¾è‘—å‡å°‘åŒ…å«å¤§é‡å·¥å…·çš„è¯·æ±‚ä½“ç§¯

### æç¤ºè¯å‹ç¼©ä¼˜åŒ–
ä»å†…å®¹å¤´å¼€å§‹æ¯”å¯¹ä¸ä¸Šæ¬¡å†…å®¹ï¼Œå°†é‡å¤éƒ¨åˆ†æ›¿æ¢ä¸ºæ ‡è®°ï¼š
- è¯†åˆ«å¹¶æ ‡è®°é‡å¤çš„æç¤ºè¯å‰ç¼€
- å‡å°‘é‡å¤ä¼ è¾“ç›¸åŒå†…å®¹
- ç‰¹åˆ«é€‚åˆå¯¹è¯å¼åº”ç”¨çš„è¿ç»­è¯·æ±‚

### HTTP ä¼ è¾“å‹ç¼©
å¯ç”¨ HTTP è¯·æ±‚çš„ `Accept-Encoding: gzip, deflate, br` å¤´ï¼Œè‡ªåŠ¨å¤„ç†æœåŠ¡å™¨å‹ç¼©å“åº”ï¼š
- æ˜¾è‘—å‡å°‘ç½‘ç»œä¼ è¾“æ•°æ®é‡
- æé«˜å›½é™… API è°ƒç”¨çš„é€Ÿåº¦
- æ”¯æŒå…¨å±€å’Œåç«¯çº§é…ç½®

## ğŸ“ é¡¹ç›®æ–‡ä»¶ç»“æ„

```
smart_ollama_proxy/
â”œâ”€â”€ ğŸš€ æ ¸å¿ƒæ–‡ä»¶
â”‚   â”œâ”€â”€ main.py                    # FastAPI åº”ç”¨å…¥å£ç‚¹
â”‚   â”œâ”€â”€ config.yaml               # ä¸»é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.local.example.yml   # æœ¬åœ°é…ç½®æ–‡ä»¶ç¤ºä¾‹
â”‚   â”œâ”€â”€ config_loader.py          # é…ç½®åŠ è½½ã€æ¨¡å‹è·¯ç”±ã€ç¯å¢ƒå˜é‡æ”¯æŒ
â”‚   â”œâ”€â”€ client_pool.py            # HTTP å®¢æˆ·ç«¯æ± ç®¡ç†
â”‚   â”œâ”€â”€ smart_logger.py           # æ™ºèƒ½ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
â”‚   â”œâ”€â”€ utils.py                  # å·¥å…·å‡½æ•°ï¼ˆJSON å¤„ç†ã€Unicode æ¸…ç†ï¼‰
â”‚   â”œâ”€â”€ requirements.txt          # Python ä¾èµ–
â”‚   â”œâ”€â”€ run.bat                   # Windows å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ README.md                 # æœ¬æ–‡æ¡£
â”‚   â”œâ”€â”€ AGENTS.md                 # AI ä»£ç†å¼€å‘æŒ‡å—
â”‚   â””â”€â”€ PERSONAL_DEVELOPMENT.md   # ä¸ªäººå¼€å‘åˆ†æ”¯ä½¿ç”¨æŒ‡å—
â”‚
â”œâ”€â”€ ğŸ› ï¸ è·¯ç”±å™¨æ¨¡å— (routers/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_router.py            # åç«¯è·¯ç”±å™¨æŠ½è±¡åŸºç±»
â”‚   â”œâ”€â”€ backend_router_factory.py # åç«¯è·¯ç”±å™¨å·¥å‚
â”‚   â”œâ”€â”€ openai_router.py          # OpenAI å…¼å®¹ API è·¯ç”±å™¨
â”‚   â”œâ”€â”€ litellm_router.py         # LiteLLM SDK è·¯ç”±å™¨
â”‚   â”œâ”€â”€ ollama_router.py          # æœ¬åœ° Ollama è·¯ç”±å™¨
â”‚   â”œâ”€â”€ mock_router.py            # æ¨¡æ‹Ÿè·¯ç”±å™¨ï¼ˆæµ‹è¯•ç”¨ï¼‰
â”‚   â””â”€â”€ core/                     # æ ¸å¿ƒç»„ä»¶
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ cache_manager.py      # å·¥å…·å’Œæç¤ºè¯ç¼“å­˜ç®¡ç†
â”‚       â”œâ”€â”€ client_manager.py     # HTTP å®¢æˆ·ç«¯ç®¡ç†
â”‚       â””â”€â”€ response_converter.py # å“åº”æ ¼å¼è½¬æ¢å™¨
â”‚
â”œâ”€â”€ ğŸ§ª æµ‹è¯•æ–‡ä»¶ (tests/)
â”‚   â”œâ”€â”€ test_api.py              # API ç«¯ç‚¹æµ‹è¯•
â”‚   â”œâ”€â”€ test_client_pool.py      # å®¢æˆ·ç«¯æ± æµ‹è¯•
â”‚   â”œâ”€â”€ test_litellm_integration.py # LiteLLM é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_litellm_serialization.py # LiteLLM åºåˆ—åŒ–æµ‹è¯•
â”‚   â”œâ”€â”€ test_mock.py             # æ¨¡æ‹Ÿåç«¯æµ‹è¯•
â”‚   â”œâ”€â”€ test_new_architecture.py # æ–°æ¶æ„æµ‹è¯•
â”‚   â”œâ”€â”€ test_priority_fallback.py # åç«¯ä¼˜å…ˆçº§å’Œå›é€€æµ‹è¯•
â”‚   â”œâ”€â”€ test_refactor.py         # é‡æ„æµ‹è¯•
â”‚   â””â”€â”€ verify_fixes.py          # ä¿®å¤éªŒè¯æµ‹è¯•
â”‚
â”œâ”€â”€ ğŸ“Š æ—¥å¿—ç›®å½• (logs/)           # æ—¥å¿—æ–‡ä»¶å­˜å‚¨ç›®å½•
â”œâ”€â”€ ğŸ”§ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ .env.example             # ç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶
â”‚   â””â”€â”€ .gitignore               # Git å¿½ç•¥æ–‡ä»¶é…ç½®
â””â”€â”€ ğŸ› ï¸ å¼€å‘å·¥å…·
    â”œâ”€â”€ test_logger_fix.py       # æ—¥å¿—ä¿®å¤æµ‹è¯•
    â”œâ”€â”€ test_new_progressbar.py  # æ–°è¿›åº¦æ¡æµ‹è¯•
    â””â”€â”€ test_progressbar.py      # è¿›åº¦æ¡æµ‹è¯•
```

## ğŸ”§ å¼€å‘æŒ‡å—

### ä¸ªäººå¼€å‘åˆ†æ”¯
é¡¹ç›®æ”¯æŒä¸ªäººå¼€å‘åˆ†æ”¯ï¼Œå…è®¸å¼€å‘è€…ä½¿ç”¨è‡ªå·±çš„ API å¯†é’¥è€Œä¸å½±å“ä¸»é…ç½®ï¼š
1. åˆ›å»º `config.local.yaml` æ–‡ä»¶
2. ä»…è¦†ç›–éœ€è¦çš„é…ç½®éƒ¨åˆ†
3. é…ç½®æ–‡ä»¶è¢« `.gitignore` æ’é™¤ï¼Œä¸ä¼šæäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶

è¯¦ç»†æŒ‡å—è¯·å‚è€ƒ [PERSONAL_DEVELOPMENT.md](PERSONAL_DEVELOPMENT.md)ã€‚

### è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
python -m pytest tests/test_api.py -v

# è¿è¡Œå•ä¸ªæµ‹è¯•å‡½æ•°
python -m pytest tests/test_api.py::test_api_endpoints -v

# å¸¦è¦†ç›–ç‡æµ‹è¯•
python -m pytest tests/ --cov=. --cov-report=html
```

### ä»£ç è§„èŒƒ
- éµå¾ª PEP 8 ç¼–ç è§„èŒƒ
- ä½¿ç”¨ç±»å‹æ³¨è§£ï¼ˆPython 3.7+ï¼‰
- ä¸ºæ–°åŠŸèƒ½æ·»åŠ æµ‹è¯•
- æ›´æ–°ç›¸å…³æ–‡æ¡£

### æ·»åŠ æ–°çš„æ¨¡å‹æä¾›å•†
1. åœ¨ `config.yaml` ä¸­æ·»åŠ æ–°çš„æ¨¡å‹ç»„é…ç½®
2. æ ¹æ®éœ€è¦æ·»åŠ æ–°çš„è·¯ç”±å™¨å®ç°ï¼ˆå¯é€‰ï¼‰
3. æ›´æ–° `config_loader.py` ä¸­çš„æ¨¡å‹è·¯ç”±é€»è¾‘
4. æ·»åŠ ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹

## ğŸ“Š æ”¯æŒçš„æ¨¡å‹æä¾›å•†

- **DeepSeek**: deepseek-chat, deepseek-reasonerï¼ˆæ”¯æŒ thinking èƒ½åŠ›ï¼‰
- **ç¡…åŸºæµåŠ¨**: deepseek-ai/DeepSeek-V3.2
- **é€šä¹‰åƒé—®**: qwen3-max, qwen3-coder-flash, qwen3-coder-plus
- **OpenAI**: gpt-4o, gpt-4o-mini, gpt-3.5-turboï¼ˆéœ€å–æ¶ˆæ³¨é‡Šé…ç½®ï¼‰
- **Anthropic**: claude-3-5-sonnet, claude-3-opusï¼ˆéœ€å–æ¶ˆæ³¨é‡Šé…ç½®ï¼‰
- **Groq**: llama-3.3-70b, mixtral-8x7bï¼ˆéœ€å–æ¶ˆæ³¨é‡Šé…ç½®ï¼‰
- **æœ¬åœ° Ollama**: æ”¯æŒæ‰€æœ‰ Ollama æ¨¡å‹

## â— å¸¸è§é—®é¢˜

### 1. é…ç½®åŠ è½½å¤±è´¥
- **æ£€æŸ¥ YAML è¯­æ³•**: `python -c "import yaml; yaml.safe_load(open('config.yaml'))"`
- **æ£€æŸ¥ç¼©è¿›æ ¼å¼**: YAML å¯¹ç¼©è¿›è¦æ±‚ä¸¥æ ¼
- **éªŒè¯æ–‡ä»¶ç¼–ç **: ä½¿ç”¨ UTF-8 ç¼–ç 

### 2. API è¯·æ±‚å¤±è´¥
- **æ£€æŸ¥ API å¯†é’¥**: ç¡®ä¿é…ç½®æ­£ç¡®æˆ–ç¯å¢ƒå˜é‡å·²è®¾ç½®
- **æ£€æŸ¥ç½‘ç»œè¿æ¥**: ç¡®ä¿å¯ä»¥è®¿é—®å¯¹åº”çš„ API æœåŠ¡
- **æŸ¥çœ‹è¯¦ç»†æ—¥å¿—**: åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® `log_level: "DEBUG"`

### 3. æ¨¡å‹æœªæ‰¾åˆ°
- **æ£€æŸ¥æ¨¡å‹åˆ—è¡¨**: `curl http://localhost:11435/api/tags`
- **éªŒè¯æ¨¡å‹é…ç½®**: æ£€æŸ¥ `config.yaml` ä¸­çš„æ¨¡å‹é…ç½®
- **æ£€æŸ¥æ¨¡å‹ç»„åç§°**: ç¡®ä¿è¯·æ±‚çš„æ¨¡å‹å±äºå·²é…ç½®çš„æ¨¡å‹ç»„

### 4. æœ¬åœ° Ollama è¿æ¥å¤±è´¥
- **æ£€æŸ¥ Ollama æœåŠ¡**: è¿è¡Œ `curl http://localhost:11434/api/tags`
- **éªŒè¯é…ç½®**: æ£€æŸ¥ `local_ollama.base_url` é…ç½®
- **å®‰è£… Ollama**: å¯ä» https://ollama.com/ ä¸‹è½½å®‰è£…

### 5. GitHub Copilot è¿æ¥é—®é¢˜
- **æ£€æŸ¥ä»£ç†æœåŠ¡**: `curl http://localhost:11435/`
- **éªŒè¯é…ç½®**: ç¡®ä¿ Copilot è®¾ç½®ä¸­çš„ Ollama åœ°å€ä¸º `http://localhost:11435`
- **æ£€æŸ¥é˜²ç«å¢™**: ç¡®ä¿ç«¯å£ 11435 æœªè¢«é˜»æ­¢

### è°ƒè¯•å»ºè®®
- **å¯ç”¨è°ƒè¯•æ—¥å¿—**: åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® `log_level: "DEBUG"`
- **æ£€æŸ¥æœåŠ¡çŠ¶æ€**: `curl http://localhost:11435/health`
- **éªŒè¯æ¨¡å‹åˆ—è¡¨**: `curl http://localhost:11435/api/tags`
- **æŸ¥çœ‹å®¢æˆ·ç«¯æ± çŠ¶æ€**: `curl http://localhost:11435/api/client-pool`

## ğŸ“œ è®¸å¯è¯

MIT License

```
Copyright (c) 2026 Smart Ollama Proxy Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¸ºé¡¹ç›®åšè´¡çŒ®ï¼š
- æŠ¥å‘Š bug å’Œé—®é¢˜
- æäº¤åŠŸèƒ½è¯·æ±‚
- æäº¤ä»£ç æ”¹è¿›å’Œä¿®å¤
- æ”¹è¿›æ–‡æ¡£

### å¼€å‘è§„èŒƒ
- éµå¾ª PEP 8 ç¼–ç è§„èŒƒ
- ä½¿ç”¨ç±»å‹æ³¨è§£
- ä¸ºæ–°åŠŸèƒ½æ·»åŠ æµ‹è¯•
- æ›´æ–°ç›¸å…³æ–‡æ¡£

æ„Ÿè°¢æ‰€æœ‰ä¸ºé¡¹ç›®åšå‡ºè´¡çŒ®çš„äººï¼

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®å’Œå·¥å…·çš„æ”¯æŒï¼š
- [FastAPI](https://fastapi.tiangolo.com/) - ç°ä»£ã€å¿«é€Ÿçš„ Web æ¡†æ¶
- [Ollama](https://ollama.com/) - æœ¬åœ° AI æ¨¡å‹è¿è¡Œå¹³å°
- [httpx](https://www.python-httpx.org/) - ä¸‹ä¸€ä»£ Python HTTP å®¢æˆ·ç«¯
- [Pydantic](https://docs.pydantic.dev/) - æ•°æ®éªŒè¯å’Œè®¾ç½®ç®¡ç†
- [LiteLLM](https://github.com/BerriAI/litellm) - ç»Ÿä¸€ AI API è°ƒç”¨åº“
- [DeepSeek](https://platform.deepseek.com/) - ä¼˜è´¨çš„ AI æ¨¡å‹æä¾›å•†
- [GitHub Copilot](https://github.com/features/copilot) - AI ç¼–ç¨‹åŠ©æ‰‹
- [é€šä¹‰åƒé—®](https://tongyi.aliyun.com/) - é˜¿é‡Œäº‘ AI æ¨¡å‹æœåŠ¡
- [ç¡…åŸºæµåŠ¨](https://siliconflow.cn/) - å›½å†… AI æ¨¡å‹æœåŠ¡å¹³å°

---
**ğŸ’¡ æç¤º**: æ›´å¤šæŠ€æœ¯ç»†èŠ‚å’Œå¼€å‘æŒ‡å—è¯·å‚è€ƒ [AGENTS.md](AGENTS.md) å’Œ [PERSONAL_DEVELOPMENT.md](PERSONAL_DEVELOPMENT.md)ã€‚